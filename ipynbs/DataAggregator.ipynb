{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_aggregator(sampleName):\n",
    "    \"\"\"\n",
    "    This function takes in a sample name and parses through the files containing cleaned .txt files pertaining to the\n",
    "    sample. It then combines the separate 2D scan arrays as a single 3D array. Finally, it writes this 3D array to a\n",
    "    new file.\n",
    "    \n",
    "    inputs: a string variable of the sample's identification\n",
    "    \n",
    "    outputs: the 3D array containing the aggregated data\n",
    "        *writes a new file in the directory corresponding to aggregated data\n",
    "    \"\"\"\n",
    "    \n",
    "    adh = np.genfromtxt('../Data/AFM/CleanedTXT/Adhesion/%s.txt'% (sampleName))\n",
    "    defor = np.genfromtxt('../Data/AFM/CleanedTXT/Deformation/%s.txt'% (sampleName))\n",
    "    dis = np.genfromtxt('../Data/AFM/CleanedTXT/Dissipation/%s.txt'% (sampleName))\n",
    "    modul = np.genfromtxt('../Data/AFM/CleanedTXT/LogDMTModulus/%s.txt'% (sampleName))\n",
    "    stif = np.genfromtxt('../Data/AFM/CleanedTXT/Stiffness/%s.txt'% (sampleName))\n",
    "\n",
    "    x, y = adh.shape\n",
    "    z = 5\n",
    "    \n",
    "    aggr = np.ndarray([x, y, z])\n",
    "    \n",
    "    for i in range(x):\n",
    "        for j in range(y):\n",
    "            aggr[i, j, 0] = adh[i, j]\n",
    "\n",
    "    for i in range(x):\n",
    "        for j in range(y):\n",
    "            aggr[i, j, 1] = defor[i, j]\n",
    "\n",
    "    for i in range(x):\n",
    "        for j in range(y):\n",
    "            aggr[i, j, 2] = dis[i, j]\n",
    "\n",
    "    for i in range(x):\n",
    "        for j in range(y):\n",
    "            aggr[i, j, 3] = modul[i, j]\n",
    "\n",
    "    for i in range(x):\n",
    "        for j in range(y):\n",
    "            aggr[i, j, 4] = stif[i, j]\n",
    "            \n",
    "    %store aggr > '../Data/AFM/AggregatedData/Control.txt'\n",
    "    \n",
    "    return aggr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adh = np.genfromtxt('../Data/AFM/CleanedTXT/Adhesion/Control.txt')\n",
    "defor = np.genfromtxt('../Data/AFM/CleanedTXT/Deformation/Control.txt')\n",
    "dis = np.genfromtxt('../Data/AFM/CleanedTXT/Dissipation/Control.txt')\n",
    "modul = np.genfromtxt('../Data/AFM/CleanedTXT/LogDMTModulus/Control.txt')\n",
    "stif = np.genfromtxt('../Data/AFM/CleanedTXT/Stiffness/Control.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n",
      "768\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "x, y = adh.shape\n",
    "z = 5\n",
    "\n",
    "print (x)\n",
    "print (y)\n",
    "print (z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aggr = np.ndarray([x, y, z])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(x):\n",
    "    for j in range(y):\n",
    "        aggr[i, j, 0] = adh[i, j]\n",
    "        \n",
    "for i in range(x):\n",
    "    for j in range(y):\n",
    "        aggr[i, j, 1] = defor[i, j]\n",
    "        \n",
    "for i in range(x):\n",
    "    for j in range(y):\n",
    "        aggr[i, j, 2] = dis[i, j]\n",
    "        \n",
    "for i in range(x):\n",
    "    for j in range(y):\n",
    "        aggr[i, j, 3] = modul[i, j]\n",
    "        \n",
    "for i in range(x):\n",
    "    for j in range(y):\n",
    "        aggr[i, j, 4] = stif[i, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.80000000e-04,  -1.31050000e-10,   1.28800000e-02,\n",
       "         1.37880000e-03,   1.09020000e-03])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggr[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  2.80000000e-04  -1.31050000e-10   1.28800000e-02   1.37880000e-03\n",
      "     1.09020000e-03]\n",
      "  [  1.02960000e-03  -7.58190000e-11  -2.76740000e-03   2.04290000e-02\n",
      "     1.67210000e-02]\n",
      "  [  1.02910000e-03  -7.55780000e-11  -2.79020000e-03   1.84840000e-02\n",
      "     1.67270000e-02]\n",
      "  ..., \n",
      "  [ -1.80620000e-03  -1.74360000e-12   5.02780000e-03   4.42590000e-03\n",
      "     3.76450000e-03]\n",
      "  [ -1.79770000e-03  -1.71660000e-12   5.01760000e-03   4.44070000e-03\n",
      "     3.78340000e-03]\n",
      "  [ -6.64150000e-04   1.90760000e-10   5.00730000e-03   5.92040000e-03\n",
      "     3.80240000e-03]]\n",
      "\n",
      " [[  1.68690000e-03  -7.34720000e-11   6.94480000e-03   2.35590000e-02\n",
      "     3.33450000e-02]\n",
      "  [  2.43670000e-03  -2.74940000e-11   6.91740000e-03   2.06280000e-02\n",
      "     1.77210000e-02]\n",
      "  [  3.18640000e-03   5.51400000e-11  -9.22220000e-04   1.57440000e-02\n",
      "     1.77210000e-02]\n",
      "  ..., \n",
      "  [ -3.08000000e-04   7.54740000e-11   8.67460000e-04  -2.79980000e-03\n",
      "    -2.06070000e-03]\n",
      "  [ -1.04650000e-03  -3.42840000e-11  -1.47970000e-02  -2.67190000e-02\n",
      "    -3.33040000e-02]\n",
      "  [ -1.03500000e-03  -3.40710000e-11  -1.48360000e-02  -2.67120000e-02\n",
      "    -3.32980000e-02]]\n",
      "\n",
      " [[  6.40770000e-04   1.55390000e-10   1.00940000e-03   1.24060000e-02\n",
      "     2.10120000e-02]\n",
      "  [  6.44570000e-04   1.00550000e-10   1.66020000e-02   6.53020000e-03\n",
      "     5.36690000e-03]\n",
      "  [  2.73350000e-04   8.23600000e-11   9.45770000e-04   1.13960000e-02\n",
      "     5.34690000e-03]\n",
      "  ..., \n",
      "  [ -1.48350000e-03   1.87790000e-10   5.90390000e-03  -7.23710000e-03\n",
      "    -1.55300000e-02]\n",
      "  [ -1.47650000e-03   1.87930000e-10   5.89540000e-03  -7.21810000e-03\n",
      "    -1.55080000e-02]\n",
      "  [ -7.19460000e-04   2.98050000e-10   5.88700000e-03   6.96090000e-03\n",
      "     1.57650000e-02]]\n",
      "\n",
      " ..., \n",
      " [[ -3.02790000e-03   1.02870000e-10   5.08970000e-03  -3.18470000e-03\n",
      "    -2.12130000e-03]\n",
      "  [ -3.40690000e-03   8.47400000e-11   5.07770000e-03   3.12370000e-03\n",
      "    -2.17230000e-03]\n",
      "  [ -3.03590000e-03   1.94910000e-10  -1.05590000e-02   2.10830000e-03\n",
      "    -2.22290000e-03]\n",
      "  ..., \n",
      "  [  1.30000000e-03  -1.56100000e-10   4.14510000e-03   2.30960000e-04\n",
      "    -2.13350000e-03]\n",
      "  [  5.56860000e-04  -1.01100000e-10   4.16740000e-03  -1.64700000e-02\n",
      "    -1.78670000e-02]\n",
      "  [  5.63700000e-04  -1.01090000e-10   4.18980000e-03  -1.65710000e-02\n",
      "    -1.79750000e-02]]\n",
      "\n",
      " [[ -1.05320000e-03   2.71060000e-11   1.05320000e-02  -9.52650000e-04\n",
      "    -3.30820000e-03]\n",
      "  [ -1.05560000e-03   1.81110000e-11   1.05140000e-02  -5.89060000e-03\n",
      "    -3.36950000e-03]\n",
      "  [ -1.80800000e-03  -5.50350000e-11  -5.12930000e-03  -9.85160000e-03\n",
      "    -3.43050000e-03]\n",
      "  ..., \n",
      "  [  5.14800000e-05  -1.60390000e-10   4.35700000e-03  -1.77100000e-03\n",
      "    -3.95250000e-03]\n",
      "  [  8.07040000e-04   5.05320000e-11   4.37240000e-03   6.44500000e-03\n",
      "     1.15710000e-02]\n",
      "  [  8.12630000e-04   5.06730000e-11   4.38780000e-03   6.35990000e-03\n",
      "     1.14700000e-02]]\n",
      "\n",
      " [[  1.54750000e-04   2.19580000e-10  -7.10430000e-03  -1.14650000e-02\n",
      "    -1.81460000e-02]\n",
      "  [ -1.72400000e-03   1.46270000e-10  -7.11030000e-03  -6.60370000e-03\n",
      "    -2.53940000e-03]\n",
      "  [ -1.72780000e-03   6.37930000e-11  -7.11640000e-03   6.98890000e-04\n",
      "    -2.55760000e-03]\n",
      "  ..., \n",
      "  [ -2.16690000e-03  -9.45980000e-11   2.84740000e-03  -2.38160000e-02\n",
      "    -3.30880000e-02]\n",
      "  [ -2.16020000e-03  -1.17350000e-11   2.85200000e-03  -1.17290000e-02\n",
      "    -1.76050000e-02]\n",
      "  [ -2.15350000e-03  -1.13500000e-11   2.85660000e-03  -1.18500000e-02\n",
      "    -1.77480000e-02]]]\n"
     ]
    }
   ],
   "source": [
    "print (aggr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'aggr' (ndarray) to file '../Data/AFM/AggregatedData/Control.txt'.\n"
     ]
    }
   ],
   "source": [
    "%store aggr > '../Data/AFM/AggregatedData/Control.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<hr/>\n",
    "### functions needed:  Bold = complete. Function name at end of description\n",
    "`check_size` : check if the size of the input is equal to 768x768, if not add the missing rows/colns using the mean value \n",
    "\n",
    "`check_missing_pixels`: check if there is NaN value and add the missing pixels using the mean value\n",
    "\n",
    "**`aggregate`: aggregate all types of data(dissipation, LogModulus, Stifffness, deformation, adhesion)into one pixel**\n",
    "\n",
    "**`aggregate_all`: a wrapper functions that call `aggregate` and agrregate all the data and store them**\n",
    "\n",
    "`normalize`: normalize the data based on the maximum vlaue without changing the original data set\n",
    "\n",
    "`reduce_dimension`: Use principal component analysis (PCA) to reduce the dimensionality of each pixel\n",
    "\n",
    "`reduce_all_dimension`: a wrapper funciton that call `reduce_dimension` recursively to reduce the dimension of all pixels of a image\n",
    "\n",
    "`draw_reduce_dimension`: plot image after PCA anaysis (CMYK)\n",
    "\n",
    "`get_info_from_neighbors`: compare value at a single pixel to its neighbors\n",
    "\n",
    "`neighbors_info`: a wrapper function that call `get_info_from_neighbors` recursively to gather informaiton for the whole image(excluding edge pixels)\n",
    "\n",
    "**`euclidean_distance`: a function that calculates the euclidean distance between two pixels**\n",
    "\n",
    "`classify_pixel`: determine whether a pixel is crystalline or not based on the control value(lower bound) and crystalline value(upper bound)\n",
    "\n",
    "`classify_image`: a wrapper function that call `classify_pixel` recursively to classify the whole image\n",
    "\n",
    "`draw_classified_image`: visualize the classified data\n",
    "\n",
    "`euclidean_classifier`: a function that considers the normalized euclidean distance in its classification\n",
    "\n",
    "`neighbor_identity_classifier`: a function that considers the classification of its neighbors in its classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## List of Functions and Descriptions##\n",
    "\n",
    "   `data_aggregator`: This function takes in a sample name and parses through the files containing cleaned .txt files pertaining to thesample. It then combines the separate 2D scan arrays as a single 3D array. Finally, it writes this 3D array to a new file.\n",
    "   \n",
    "   `find_maxes`: This function takes in a 3D array of intensity values for pixels in an AFM micrograph and returns the maximum value for each of the scan types as a vector\n",
    "   \n",
    "   `euclidean_distance`: This function takes in a vector of maximum values for the sample's different data types and two pixels as vectors of their features and calculates the Euclidean distance. It then normalizes these differences for each scan type so there isn't uneven weighting for a given feature type. Finally, it returns the adjusted Euclidean distance.\n",
    "   \n",
    "   `neighbor_locator`: This function takes in the xy location of a pixel in a 3D array of information and locates its neighbors, returning these locations as a 2D array of 8 different xy coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
